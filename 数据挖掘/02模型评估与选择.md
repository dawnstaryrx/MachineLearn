# 模型选择与评估

## 1 经验误差和过拟合

错误率和误差：

1. **错误率**：错分样本所占的比率。
2. **精度**：1-错误率。
3. **误差**：样本真实输出与预测输出之间的差异。
   1. **训练误差**：训练集上的误差。
   2. **测试误差**：测试集上的误差。
   3. **泛化误差**：除训练集外所有样本或者新样本的误差。
   4. 注意：由于事先并不知道新样本的特征，我们只能努力使**经验误差最小化**。
   5. 很多时候虽然能在训练集上做到分类错误率为0，但多数情况下，这样的学习器**并不好**。

---

过拟合：

1. 过拟合：
   1. 定义：学习器把训练样本学习的“太好”，将训练样本本身的特点当作所有样本的一般性质，导致泛化能力下降。
   2. 缓解过拟合：（过拟合无法避免，只能缓解）
      1. 优化目标加正则项；
      2. 提前停止算法。
2. 欠拟合：
   1. 定义：对训练样本的一般性质尚未学好。
   2. 改善：
      1. 决策树：拓展分支
      2. 神经网络：增加训练轮数
3. 模型选择

## 2 评估方法

1. 我们可以通过实验测试来对学习器的泛化误差进行评估进而做出选择。
2. 为此，需要一个**测试集**来测试学习器对新样本的判断能力，以测试集上的“测试误差”作为泛化误差的近似。
3. 测试集要和训练集中的样本尽量互斥。
4. m个样本 S训练集 T测试集

方法：

1. 留出法
   1. 直接将数据划分为两个互斥集合S and T；
   2. 训练集/测试集划分尽可能保持数据分布的一致性；
   3. 一般若干次随即划分，重复实验取平均值；
   4. 训练/测试样本比例通常2:1~4:1
2. 交叉验证法
   1. 将数据集分层采样划分为k个大小相似的互斥子集；
   2. 每次用k-1个子集的并集作为训练集，余下的子集作为测试集，最终返回k个测试结果的均值；
   3. k最常用的取值是10——10折交叉验证法。
3. p次k折交叉验证法
   1. 为了减小因样本划分不同而引入的差别。
   2. k折交叉验证通常随机使用不同的划分重复p次，最终的评估结果是其均值。
4. 留一法
   1. m个样本，令k=m
   2. 不受随机样本划分方式的影响；
   3. 结果往往比较准确；
   4. 当数据集比较大时，计算开销难以忍受。
5. 自助法
   1. 以自主采样法为基础，对数据集D有放回采样m次得到训练集D'，D\D'用作测试集。
   2. 自主采样法：
      1. 每次随机从D中挑选一个样本，将其拷贝放入D'；
      2. 然后将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到；
      3. 这个过程重复m次，得到包含m个样本的数据集D'。
   3. 实际模型与预测模型都使用m个训练样本；
   4. 约有1/3的样本没在训练集中出现；
   5. 从初始数据集中产生多个不同的训练集，对集成学习有很大好处；
   6. 自助法在数据集较小、难以有效划分训练/测试集时，有用。
   7. 由于改变了数据集分布可能引入估计偏差，在数据量足够时，留出法和交叉验证法更常用。

## 3 性能度量

定义

1. 性能度量：对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的标准。
2. 性能度量是衡量模型泛化能力的评估标准，反映了任务需求。
3. 使用不同的性能度量往往会得到不同的判断结果。

几种性能度量

1. 回归任务
   1. 均方误差
2. 分类任务
   1. 错误率
   2. 精度
   3. **查准率，查全率，混淆矩阵**P30公式
      1. 
   4. 查准率和查全率是一对矛盾的量。
   5. 查准率-查全率曲线，P-R图——被包住的性能好，平衡点越大性能越好。
   6. F1度量
   7. ROC曲线——以假正例率为横轴，真正例率为纵轴。

## 4 比较检验

关于性能比较：

1. 测试性能并不等于泛化性能；
2. 测试性能随着测试集的变化而变化；
3. 很多机器学习算法本身有一定的随机性。
4. 因此，直接选取相应评估方法在相应度量下比较大小的方法不可取，需要假设检验！
  
假设检验为学习器性能比较提供了重要依据，基于其结果我们可以推出：  
若在测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。  

比较检验的方法：

1. 二项检验
2. t检验
3. 交叉验证t检验
4. “偏差-方差分解”用来解释泛化性能 （泛化误差可分解为偏差、方差、噪声的和）
   1. 偏差刻画了学习算法本身的拟合能力；
   2. 方差刻画了数据扰动造成的影响；
   3. 噪声-当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。
   4. 偏差-方差窘境。

归一化与标准化

1. 归一化——最大最小规范化，会改变特征数据分布；
2. Z-score标准化，不会改变。
